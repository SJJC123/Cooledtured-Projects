{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Anime Websites:\n",
        "1. Kitso - https://kitsu.app/explore/anime\n",
        "2. My Animel List (top anime airing) - https://myanimelist.net/topanime.php?type=airing\n",
        "3. Anilist\n",
        "4. Ranker (many lists; this one is best anime airing right now) https://www.ranker.com/list/best-current-anime-airing-now/ranker-anime\n",
        "5. **My Anime List** (top anime in general) https://myanimelist.net/topanime.php\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "e1Rrz_qT37fZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Anime Top 10 List Code"
      ],
      "metadata": {
        "id": "05pIvxybFMAf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Instructions\n",
        "1. **Everything you need is here on colab**.\n",
        "\n",
        "2. Run (**hit the play button**) the code that starts with '!pip'. It will install **rapidfuzz** (a python library) onto your system that's needed in order for the anime list code to work. You only have to do this once. Every other time you run this code in this colab you can just run the anime code and won't need to run '!pip'\n",
        "\n",
        "3. Run the code for the anime list (**the really long piece of code; the second code block in this colab**).\n",
        "\n",
        "4. If it works correctly, you'll get a top 10 list as your output\n",
        "\n",
        "5.  Run the last code block (third one). It will save the code output (anime list) as a 'csv' file to your computer so that you will have the list for every instance that you run it. Ex: 'top_10_grouped_anime.csv'\n",
        "\n",
        "# Potential Errors\n",
        "1. If you experience any error dealing with the library rapidfuzz, just run the '!pip install rapidfuzz' line of code again and then the anime codeblock.\n",
        "\n"
      ],
      "metadata": {
        "id": "UsDWQwU4FOnX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# RUN THIS CODE FIRST; you only have to do it once for the first time and then rapidfuzz will be installed in your system for good\n",
        "# If it's already downloaded, you're good to go\n",
        "!pip install rapidfuzz"
      ],
      "metadata": {
        "id": "sMgUbDCqFSm1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "528648e9-7cb3-444d-af0a-2be6160aaca9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rapidfuzz\n",
            "  Downloading rapidfuzz-3.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Downloading rapidfuzz-3.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/3.1 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/3.1 MB\u001b[0m \u001b[31m33.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━\u001b[0m \u001b[32m2.6/3.1 MB\u001b[0m \u001b[31m35.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m32.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m22.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: rapidfuzz\n",
            "Successfully installed rapidfuzz-3.10.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mode Code for Anime"
      ],
      "metadata": {
        "id": "-t9_UGkoVkiv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import re\n",
        "from rapidfuzz import fuzz\n",
        "\n",
        "# Function to clean and normalize titles for comparison\n",
        "def normalize_title(title):\n",
        "    # Lowercase, remove special characters, and strip whitespace\n",
        "    title = title.lower()\n",
        "    title = re.sub(r'[^a-z0-9]', '', title)\n",
        "    return title\n",
        "\n",
        "# Function to get top 10 anime from MyAnimeList\n",
        "def get_top_ten_anime():\n",
        "    url = 'https://myanimelist.net/topanime.php'\n",
        "    response = requests.get(url)\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "    anime_list = soup.find_all('tr', class_='ranking-list')[:10]\n",
        "\n",
        "    top_anime = []\n",
        "    for anime in anime_list:\n",
        "        title = anime.find('h3').text.strip()\n",
        "        top_anime.append({'Source': 'MyAnimeList', 'Title': title})\n",
        "    return top_anime\n",
        "\n",
        "# Function to get top 10 airing anime from MyAnimeList\n",
        "def get_top_ten_anime_airing():\n",
        "    url = 'https://myanimelist.net/topanime.php?type=airing'\n",
        "    response = requests.get(url)\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "    anime_list = soup.find_all('tr', class_='ranking-list')[:10]\n",
        "\n",
        "    top_anime = []\n",
        "    for anime in anime_list:\n",
        "        title = anime.find('h3').text.strip()\n",
        "        top_anime.append({'Source': 'MyAnimeList (Airing)', 'Title': title})\n",
        "    return top_anime\n",
        "\n",
        "# Function to get top trending anime from Kitsu\n",
        "def get_kitsu_top_current_anime():\n",
        "    url = 'https://kitsu.io/api/edge/trending/anime'\n",
        "    response = requests.get(url)\n",
        "    data = response.json()['data']\n",
        "\n",
        "    top_current_anime = []\n",
        "    for i, anime in enumerate(data[:10]):\n",
        "        title = anime['attributes']['canonicalTitle']\n",
        "        top_current_anime.append({'Source': 'Kitsu', 'Title': title})\n",
        "    return top_current_anime\n",
        "\n",
        "# Function to get top 10 anime from AniList\n",
        "def get_anilist_top_10():\n",
        "    query = '''\n",
        "    query ($page: Int, $perPage: Int) {\n",
        "        Page(page: $page, perPage: $perPage) {\n",
        "            media(sort: SCORE_DESC, type: ANIME, status: FINISHED) {\n",
        "                title {\n",
        "                    romaji\n",
        "                    english\n",
        "                }\n",
        "                averageScore\n",
        "                popularity\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "    '''\n",
        "    variables = {'page': 1, 'perPage': 10}\n",
        "    url = 'https://graphql.anilist.co'\n",
        "    response = requests.post(url, json={'query': query, 'variables': variables})\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        data = response.json()['data']['Page']['media']\n",
        "        top_anilist = []\n",
        "        for anime in data:\n",
        "            title = anime['title']['english'] or anime['title']['romaji']\n",
        "            top_anilist.append({'Source': 'AniList', 'Title': title})\n",
        "        return top_anilist\n",
        "    else:\n",
        "        raise Exception(f\"Failed to fetch data from AniList API. Status Code: {response.status_code}\")\n",
        "\n",
        "# Function to get top 6 anime from Ranker\n",
        "def get_ranker_top_6():\n",
        "    url = 'https://www.ranker.com/list/best-current-anime-airing-now/ranker-anime'\n",
        "    response = requests.get(url)\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "    list_items = soup.find_all('li', role='listitem')\n",
        "\n",
        "    top_ranker = []\n",
        "    for item in list_items[:6]:\n",
        "        title_tag_a = item.find('a', class_='NodeNameUI_main__tvvXB')\n",
        "        title = title_tag_a['title'] if title_tag_a else item.find('h2', class_='NodeNameUI_main__tvvXB').get_text(strip=True)\n",
        "        top_ranker.append({'Source': 'Ranker', 'Title': title})\n",
        "    return top_ranker\n",
        "\n",
        "# Function to combine all lists and normalize titles\n",
        "def combine_anime_lists():\n",
        "    # Gather all titles from different sources\n",
        "    top_anime_list = []\n",
        "    top_anime_list.extend(get_top_ten_anime())\n",
        "    top_anime_list.extend(get_top_ten_anime_airing())\n",
        "    top_anime_list.extend(get_kitsu_top_current_anime())\n",
        "    top_anime_list.extend(get_anilist_top_10())\n",
        "    top_anime_list.extend(get_ranker_top_6())\n",
        "\n",
        "    # Normalize titles for comparison\n",
        "    for anime in top_anime_list:\n",
        "        anime['NormalizedTitle'] = normalize_title(anime['Title'])\n",
        "\n",
        "    return top_anime_list\n",
        "\n",
        "# Function to group similar titles based on fuzzy matching and substring matching\n",
        "def group_similar_titles(anime_list, threshold=85):\n",
        "    grouped_anime = []\n",
        "    grouped_titles = []\n",
        "\n",
        "    for anime in anime_list:\n",
        "        title = anime['Title']\n",
        "        normalized_title = anime['NormalizedTitle']\n",
        "\n",
        "        found_match = False\n",
        "\n",
        "        for group in grouped_anime:\n",
        "            # Use both fuzzy ratio and check if the normalized title is a substring\n",
        "            if (fuzz.ratio(normalized_title, group['NormalizedTitle']) >= threshold or\n",
        "                normalized_title in group['NormalizedTitle'] or\n",
        "                group['NormalizedTitle'] in normalized_title):\n",
        "                group['Count'] += 1\n",
        "                group['Sources'].append(anime['Source'])\n",
        "                found_match = True\n",
        "                break\n",
        "\n",
        "        if not found_match:\n",
        "            grouped_anime.append({\n",
        "                'Title': title,\n",
        "                'NormalizedTitle': normalized_title,\n",
        "                'Count': 1,\n",
        "                'Sources': [anime['Source']]\n",
        "            })\n",
        "\n",
        "    # Sort the list by frequency count in descending order\n",
        "    grouped_anime.sort(key=lambda x: x['Count'], reverse=True)\n",
        "\n",
        "    # Ensure that only one title per group of similar titles is included in the top 10\n",
        "    final_grouped_anime = []\n",
        "    used_normalized_titles = set()\n",
        "\n",
        "    for anime in grouped_anime:\n",
        "        if anime['NormalizedTitle'] not in used_normalized_titles:\n",
        "            final_grouped_anime.append(anime)\n",
        "            used_normalized_titles.add(anime['NormalizedTitle'])\n",
        "            # Stop once we have 10 unique titles\n",
        "            if len(final_grouped_anime) == 10:\n",
        "                break\n",
        "\n",
        "    return final_grouped_anime\n",
        "\n",
        "# Get combined anime list\n",
        "anime_list = combine_anime_lists()\n",
        "\n",
        "# Group similar titles and get the top 10 most frequent ones without duplicates\n",
        "top_10_anime = group_similar_titles(anime_list)\n",
        "\n",
        "# Top 10 results\n",
        "df_top_10 = pd.DataFrame(top_10_anime)\n",
        "print(df_top_10)\n",
        "\n",
        "# save the result as a csv on colab\n",
        "df_top_10.to_csv('top_10_grouped_anime.csv', index=False)\n"
      ],
      "metadata": {
        "id": "8Gv-S_R4FSkj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dea74f46-440a-45a2-b32c-42cc41776f53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                     Title                  NormalizedTitle  \\\n",
            "0                                 Gintama°                          gintama   \n",
            "1         Fullmetal Alchemist: Brotherhood    fullmetalalchemistbrotherhood   \n",
            "2                  Boku no Hero Academia 2              bokunoheroacademia2   \n",
            "3  Bleach: Sennen Kessen-hen - Soukoku-tan  bleachsennenkessenhensoukokutan   \n",
            "4                              Steins;Gate                       steinsgate   \n",
            "5                   Hunter x Hunter (2011)                hunterxhunter2011   \n",
            "6                                One Piece                         onepiece   \n",
            "7                                 Dandadan                         dandadan   \n",
            "8                          Attack on Titan                    attackontitan   \n",
            "9                        Sousou no Frieren                  sousounofrieren   \n",
            "\n",
            "   Count                                            Sources  \n",
            "0      6  [MyAnimeList, MyAnimeList, MyAnimeList, MyAnim...  \n",
            "1      3                      [MyAnimeList, Kitsu, AniList]  \n",
            "2      3                              [Kitsu, Kitsu, Kitsu]  \n",
            "3      2                [MyAnimeList, MyAnimeList (Airing)]  \n",
            "4      2                             [MyAnimeList, AniList]  \n",
            "5      2                             [MyAnimeList, AniList]  \n",
            "6      2                      [MyAnimeList (Airing), Kitsu]  \n",
            "7      2                     [MyAnimeList (Airing), Ranker]  \n",
            "8      2                                   [Kitsu, AniList]  \n",
            "9      1                                      [MyAnimeList]  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Saves the csv file from colab to your local device (i.e. laptop, computer, phone,)\n",
        "from google.colab import files\n",
        "files.download('top_10_grouped_anime.csv')"
      ],
      "metadata": {
        "id": "L0tJhY4uFSa4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "e2ce7e53-9a58-49cb-e86c-c1fabae90cd7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_4d5a29a3-41d2-4b76-af3b-049c8dfbf99c\", \"top_10_grouped_anime.csv\", 818)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Averaging Code for Anime"
      ],
      "metadata": {
        "id": "Zi9l_inZVWCH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Average Version\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import re\n",
        "from rapidfuzz import fuzz\n",
        "\n",
        "# Function to clean and normalize titles for comparison\n",
        "def normalize_title(title):\n",
        "    # Lowercase, remove special characters, and strip whitespace\n",
        "    title = title.lower()\n",
        "    title = re.sub(r'[^a-z0-9]', '', title)\n",
        "    return title\n",
        "\n",
        "# Function to get top 10 anime from MyAnimeList\n",
        "def get_top_ten_anime():\n",
        "    url = 'https://myanimelist.net/topanime.php'\n",
        "    response = requests.get(url)\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "    anime_list = soup.find_all('tr', class_='ranking-list')[:10]\n",
        "\n",
        "    top_anime = []\n",
        "    for rank, anime in enumerate(anime_list, start=1):\n",
        "        title = anime.find('h3').text.strip()\n",
        "        weight = 11 - rank  # 1st place gets weight 10, 10th place gets weight 1\n",
        "        top_anime.append({'Source': 'MyAnimeList', 'Title': title, 'Rank': rank, 'Weight': weight})\n",
        "    return top_anime\n",
        "\n",
        "# Function to get top 10 airing anime from MyAnimeList\n",
        "def get_top_ten_anime_airing():\n",
        "    url = 'https://myanimelist.net/topanime.php?type=airing'\n",
        "    response = requests.get(url)\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "    anime_list = soup.find_all('tr', class_='ranking-list')[:10]\n",
        "\n",
        "    top_anime = []\n",
        "    for rank, anime in enumerate(anime_list, start=1):\n",
        "        title = anime.find('h3').text.strip()\n",
        "        weight = 11 - rank\n",
        "        top_anime.append({'Source': 'MyAnimeList (Airing)', 'Title': title, 'Rank': rank, 'Weight': weight})\n",
        "    return top_anime\n",
        "\n",
        "# Function to get top trending anime from Kitsu\n",
        "def get_kitsu_top_current_anime():\n",
        "    url = 'https://kitsu.io/api/edge/trending/anime'\n",
        "    response = requests.get(url)\n",
        "    data = response.json()['data']\n",
        "\n",
        "    top_current_anime = []\n",
        "    for rank, anime in enumerate(data[:10], start=1):\n",
        "        title = anime['attributes']['canonicalTitle']\n",
        "        weight = 11 - rank\n",
        "        top_current_anime.append({'Source': 'Kitsu', 'Title': title, 'Rank': rank, 'Weight': weight})\n",
        "    return top_current_anime\n",
        "\n",
        "# Function to get top 10 anime from AniList\n",
        "def get_anilist_top_10():\n",
        "    query = '''\n",
        "    query ($page: Int, $perPage: Int) {\n",
        "        Page(page: $page, perPage: $perPage) {\n",
        "            media(sort: SCORE_DESC, type: ANIME, status: FINISHED) {\n",
        "                title {\n",
        "                    romaji\n",
        "                    english\n",
        "                }\n",
        "                averageScore\n",
        "                popularity\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "    '''\n",
        "    variables = {'page': 1, 'perPage': 10}\n",
        "    url = 'https://graphql.anilist.co'\n",
        "    response = requests.post(url, json={'query': query, 'variables': variables})\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        data = response.json()['data']['Page']['media']\n",
        "        top_anilist = []\n",
        "        for rank, anime in enumerate(data, start=1):\n",
        "            title = anime['title']['english'] or anime['title']['romaji']\n",
        "            weight = 11 - rank\n",
        "            top_anilist.append({'Source': 'AniList', 'Title': title, 'Rank': rank, 'Weight': weight})\n",
        "        return top_anilist\n",
        "    else:\n",
        "        raise Exception(f\"Failed to fetch data from AniList API. Status Code: {response.status_code}\")\n",
        "\n",
        "# Function to get top 6 anime from Ranker\n",
        "def get_ranker_top_6():\n",
        "    url = 'https://www.ranker.com/list/best-current-anime-airing-now/ranker-anime'\n",
        "    response = requests.get(url)\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "    list_items = soup.find_all('li', role='listitem')\n",
        "\n",
        "    top_ranker = []\n",
        "    for rank, item in enumerate(list_items[:6], start=1):\n",
        "        title_tag_a = item.find('a', class_='NodeNameUI_main__tvvXB')\n",
        "        title = title_tag_a['title'] if title_tag_a else item.find('h2', class_='NodeNameUI_main__tvvXB').get_text(strip=True)\n",
        "        weight = 11 - rank\n",
        "        top_ranker.append({'Source': 'Ranker', 'Title': title, 'Rank': rank, 'Weight': weight})\n",
        "    return top_ranker\n",
        "\n",
        "# Function to combine all lists and normalize titles\n",
        "def combine_anime_lists():\n",
        "    # Gather all titles from different sources\n",
        "    top_anime_list = []\n",
        "    top_anime_list.extend(get_top_ten_anime())\n",
        "    top_anime_list.extend(get_top_ten_anime_airing())\n",
        "    top_anime_list.extend(get_kitsu_top_current_anime())\n",
        "    top_anime_list.extend(get_anilist_top_10())\n",
        "    top_anime_list.extend(get_ranker_top_6())\n",
        "\n",
        "    # Normalize titles for comparison\n",
        "    for anime in top_anime_list:\n",
        "        anime['NormalizedTitle'] = normalize_title(anime['Title'])\n",
        "\n",
        "    return top_anime_list\n",
        "\n",
        "# Function to group similar titles based on fuzzy matching and rank weighting\n",
        "def group_similar_titles(anime_list, threshold=85):\n",
        "    grouped_anime = []\n",
        "\n",
        "    for anime in anime_list:\n",
        "        title = anime['Title']\n",
        "        normalized_title = anime['NormalizedTitle']\n",
        "        weight = anime['Weight']\n",
        "\n",
        "        found_match = False\n",
        "\n",
        "        for group in grouped_anime:\n",
        "            # Use both fuzzy ratio and check if the normalized title is a substring\n",
        "            if (fuzz.ratio(normalized_title, group['NormalizedTitle']) >= threshold or\n",
        "                normalized_title in group['NormalizedTitle'] or\n",
        "                group['NormalizedTitle'] in normalized_title):\n",
        "                group['Weight'] += weight\n",
        "                group['Sources'].append(anime['Source'])\n",
        "                found_match = True\n",
        "                break\n",
        "\n",
        "        if not found_match:\n",
        "            grouped_anime.append({\n",
        "                'Title': title,\n",
        "                'NormalizedTitle': normalized_title,\n",
        "                'Weight': weight,\n",
        "                'Sources': [anime['Source']]\n",
        "            })\n",
        "\n",
        "    # Sort the list by weight (higher ranks) in descending order\n",
        "    grouped_anime.sort(key=lambda x: x['Weight'], reverse=True)\n",
        "\n",
        "    # Ensure that only one title per group of similar titles is included in the top 10\n",
        "    final_grouped_anime = []\n",
        "    used_normalized_titles = set()\n",
        "\n",
        "    for anime in grouped_anime:\n",
        "        if anime['NormalizedTitle'] not in used_normalized_titles:\n",
        "            final_grouped_anime.append(anime)\n",
        "            used_normalized_titles.add(anime['NormalizedTitle'])\n",
        "            # Stop once we have 10 unique titles\n",
        "            if len(final_grouped_anime) == 10:\n",
        "                break\n",
        "\n",
        "    return final_grouped_anime\n",
        "\n",
        "# Get combined anime list\n",
        "anime_list = combine_anime_lists()\n",
        "\n",
        "# Group similar titles and get the top 10 most frequent ones without duplicates\n",
        "top_10_anime = group_similar_titles(anime_list)\n",
        "\n",
        "# Top 10 results\n",
        "df_top_10 = pd.DataFrame(top_10_anime)\n",
        "print(df_top_10)\n",
        "\n",
        "# save the result as a csv on colab\n",
        "df_top_10.to_csv('top_10_grouped_anime.csv', index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DgWSCRbdVVsm",
        "outputId": "bb751935-e325-4244-bb1f-83484f02089d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                     Title                   NormalizedTitle  \\\n",
            "0                                 Gintama°                           gintama   \n",
            "1                  Boku no Hero Academia 2               bokunoheroacademia2   \n",
            "2  Bleach: Sennen Kessen-hen - Soukoku-tan   bleachsennenkessenhensoukokutan   \n",
            "3         Fullmetal Alchemist: Brotherhood     fullmetalalchemistbrotherhood   \n",
            "4                          Attack on Titan                     attackontitan   \n",
            "5                                One Piece                          onepiece   \n",
            "6                        Sousou no Frieren                   sousounofrieren   \n",
            "7            Frieren: Beyond Journey’s End          frierenbeyondjourneysend   \n",
            "8          Bleach: Thousand-Year Blood War        bleachthousandyearbloodwar   \n",
            "9  Monogatari Series: Off & Monster Season  monogatariseriesoffmonsterseason   \n",
            "\n",
            "   Weight                                            Sources  \n",
            "0      30  [MyAnimeList, MyAnimeList, MyAnimeList, MyAnim...  \n",
            "1      24                              [Kitsu, Kitsu, Kitsu]  \n",
            "2      18                [MyAnimeList, MyAnimeList (Airing)]  \n",
            "3      17                      [MyAnimeList, Kitsu, AniList]  \n",
            "4      15                                   [Kitsu, AniList]  \n",
            "5      13                      [MyAnimeList (Airing), Kitsu]  \n",
            "6      10                                      [MyAnimeList]  \n",
            "7      10                                          [AniList]  \n",
            "8      10                                           [Ranker]  \n",
            "9       9                             [MyAnimeList (Airing)]  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Saves the csv file from colab to your local device (i.e. laptop, computer, phone,)\n",
        "from google.colab import files\n",
        "files.download('top_10_grouped_anime.csv')"
      ],
      "metadata": {
        "id": "HK69g9EzVVim",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "de34d0f9-ecf9-4b9f-c8db-36507d71a6b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_c37039b1-62d5-4fcd-bbde-001960d3cb98\", \"top_10_grouped_anime.csv\", 849)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Video Game Top 10 Code"
      ],
      "metadata": {
        "id": "odaOgaieFip6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Scraping of IGN Review Ratings"
      ],
      "metadata": {
        "id": "Rp0oMuIl5B4X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "\n",
        "url = \"https://www.ign.com/reviews/games\"\n",
        "\n",
        "headers = {\n",
        "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
        "}\n",
        "\n",
        "response = requests.get(url, headers=headers)\n",
        "\n",
        "if response.status_code == 200:\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "    # Extract titles and ratings\n",
        "    titles = soup.find_all('span', class_='interface jsx-326752785 jsx-4254096439 item-title bold')\n",
        "    rating_wrappers = soup.find_all('span', class_='hexagon-content-wrapper')\n",
        "\n",
        "    # Extract ratings from the <figcaption> tags inside the rating wrappers\n",
        "    ratings = [wrapper.find('figcaption').text.strip() for wrapper in rating_wrappers if wrapper.find('figcaption')]\n",
        "\n",
        "    # Ensure ratings and titles are aligned\n",
        "    ratings = ratings[:len(titles)]\n",
        "\n",
        "    print(f\"Number of titles found: {len(titles)}\")\n",
        "    print(f\"Number of ratings found: {len(ratings)}\")\n",
        "\n",
        "    # Prepare data for DataFrame\n",
        "    data = []\n",
        "    for title, rating in zip(titles[:10], ratings[1:11]):  # Limit both to 10\n",
        "        title_text = title.text.strip().split(\" Review\")[0]  # Remove \" Review\" and everything after\n",
        "        rating_text = rating.strip()\n",
        "        data.append({'Title': title_text, 'Rating': rating_text})\n",
        "\n",
        "    # Create DataFrame\n",
        "    ign = pd.DataFrame(data)\n",
        "\n",
        "    # Print the DataFrame\n",
        "    print(\"Top 10 Reviews and Ratings DataFrame:\")\n",
        "    print(ign)\n",
        "\n",
        "else:\n",
        "    print(\"Failed to retrieve the page. Status code:\", response.status_code)\n"
      ],
      "metadata": {
        "id": "zLXM-U7UFk91",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9564d81e-0fbf-43b9-8993-bd18db829a46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of titles found: 10\n",
            "Number of ratings found: 10\n",
            "Top 10 Reviews and Ratings DataFrame:\n",
            "                              Title Rating\n",
            "0           Kong: Survivor Instinct      5\n",
            "1     A Quiet Place: The Road Ahead      7\n",
            "2        Sonic X Shadow Generations      9\n",
            "3  Starship Troopers: Extermination      6\n",
            "4              Unknown 9: Awakening      5\n",
            "5              MechWarrior 5: Clans      8\n",
            "6        Super Mario Party Jamboree      9\n",
            "7       Dragon Ball: Sparking! Zero      7\n",
            "8                        Until Dawn      5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Scraping for OpenCritic reviews. Scores has been converted from int to float to match scoring format of the other websites. For example, a score of 95 is converted to 9.5."
      ],
      "metadata": {
        "id": "FPKcaxwD5cap"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import time\n",
        "import re\n",
        "\n",
        "# Base URL for pagination\n",
        "base_url = \"https://opencritic.com/browse/all/last90/date?page={}\"\n",
        "headers = {\n",
        "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
        "}\n",
        "\n",
        "def scrape_opencritic(page_number, headers):\n",
        "    \"\"\"\n",
        "    Scrapes game titles and ratings from OpenCritic for a given page number.\n",
        "\n",
        "    Args:\n",
        "        page_number (int): The page number to scrape.\n",
        "        headers (dict): The headers to use for the HTTP request.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: A DataFrame containing game titles and ratings for the page.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        url = base_url.format(page_number)\n",
        "        response = requests.get(url, headers=headers)\n",
        "        response.raise_for_status()\n",
        "\n",
        "        soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "        titles = soup.find_all('div', class_='game-name col ml-2')\n",
        "        ratings = soup.find_all('div', class_='inner-orb small-orb')\n",
        "\n",
        "        if len(ratings) > len(titles):\n",
        "            ratings = ratings[:len(titles)]\n",
        "\n",
        "        top_ten = []\n",
        "        for title, rating in zip(titles, ratings):\n",
        "            title_text = title.text.strip()\n",
        "            rating_text = rating.text.strip()\n",
        "\n",
        "            title_text = re.sub(r'\\s*\\(\\d{4}\\)', '', title_text)\n",
        "\n",
        "            if rating_text.isdigit():\n",
        "                rating_value = float(rating_text) / 10\n",
        "                top_ten.append((title_text, rating_value))\n",
        "\n",
        "        if top_ten:\n",
        "            return pd.DataFrame(top_ten, columns=['Title', 'Rating'])\n",
        "        else:\n",
        "            print(f\"No valid ratings found on page {page_number}.\")\n",
        "            return pd.DataFrame(columns=['Title', 'Rating'])\n",
        "\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(\"An error occurred:\", e)\n",
        "        return pd.DataFrame(columns=['Title', 'Rating'])\n",
        "\n",
        "# Scrape multiple pages and combine results\n",
        "opencritic_df = pd.DataFrame()\n",
        "\n",
        "for page in range(1, 5):  # Adjust the range as needed for more pages\n",
        "    print(f\"Scraping page {page}...\")\n",
        "    page_df = scrape_opencritic(page, headers)\n",
        "    opencritic_df = pd.concat([opencritic_df, page_df], ignore_index=True)\n",
        "    time.sleep(2)  # Sleep to be polite to the server\n",
        "\n",
        "# Check the combined DataFrame\n",
        "if not opencritic_df.empty:\n",
        "    print(\"Combined Reviews and Ratings DataFrame:\")\n",
        "    print(opencritic_df)\n",
        "    # Save to CSV if needed\n",
        "    opencritic_df.to_csv('opencritic_reviews_combined.csv', index=False)\n",
        "else:\n",
        "    print(\"No data found across all pages.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VHN0cfeJX-nB",
        "outputId": "f3fe4ac9-6add-4da8-f840-fcb75737bb23"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scraping page 1...\n",
            "Scraping page 2...\n",
            "Scraping page 3...\n",
            "Scraping page 4...\n",
            "Combined Reviews and Ratings DataFrame:\n",
            "                                              Title  Rating\n",
            "0                           Kong: Survivor Instinct     6.6\n",
            "1                        Sonic X Shadow Generations     7.9\n",
            "2                                Fear The Spotlight     8.1\n",
            "3   Teenage Mutant Ninja Turtles: Mutants Unleashed     7.5\n",
            "4                        Super Mario Party Jamboree     8.1\n",
            "5                              MechWarrior 5: Clans     7.9\n",
            "6                         Killing Time: Resurrected     8.5\n",
            "7                              Unknown 9: Awakening     6.4\n",
            "8                                RetroRealms Arcade     6.9\n",
            "9                           Arizona Sunshine Remake     7.8\n",
            "10                    A Quiet Place: The Road Ahead     6.6\n",
            "11                                             Neva     8.7\n",
            "12                    Nikoderiko: The Magical World     7.5\n",
            "13                          Just Dance 2025 Edition     7.3\n",
            "14                             Drova - Forsaken Kin     7.0\n",
            "15                             Metaphor: ReFantazio     9.2\n",
            "16                                           Europa     7.5\n",
            "17                    Transformers: Galactic Trials     4.8\n",
            "18                       Dragon Ball Sparking! Zero     8.3\n",
            "19                                       Amber Isle     6.8\n",
            "20                       Sky Oceans: Wings for Hire     4.3\n",
            "21                                    Silent Hill 2     8.7\n",
            "22                      Diablo IV: Vessel of Hatred     8.5\n",
            "23                                      Dead Season     7.5\n",
            "24                                  Phoenix Springs     7.5\n",
            "25                                           NHL 25     6.8\n",
            "26                                       Until Dawn     7.0\n",
            "27             Sword Art Online: Fractured Daydream     6.8\n",
            "28                                      KILL KNIGHT     8.4\n",
            "29                                     Rogue Waters     8.3\n",
            "30                       Starfield: Shattered Space     6.1\n",
            "31                               Throne and Liberty     7.1\n",
            "32                                         REYNATIS     6.1\n",
            "33              Looney Tunes: Wacky World of Sports     4.9\n",
            "34                                      Ravenswatch     8.3\n",
            "35            The Legend of Zelda: Echoes of Wisdom     8.5\n",
            "36                                        Iron Meat     8.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Scraping for Gamespot reviews"
      ],
      "metadata": {
        "id": "paI6L86J5Rtg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "\n",
        "# Define the base URL and headers\n",
        "base_url = \"https://www.gamespot.com/games/reviews/\"\n",
        "headers = {\n",
        "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
        "}\n",
        "\n",
        "# Function to scrape a given page\n",
        "def scrape_page(url):\n",
        "    # Send GET request\n",
        "    response = requests.get(url, headers=headers)\n",
        "\n",
        "    # Check if the request was successful\n",
        "    if response.status_code == 200:\n",
        "        # Parse the HTML content\n",
        "        soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "        # Extract titles from different formats\n",
        "        first_title = soup.find('h2')  # First title\n",
        "        additional_titles = soup.find_all('h3', class_='media-title vertical-spacing-small-top-rem')\n",
        "        original_titles = soup.find_all('h4', class_='card-item__title')\n",
        "\n",
        "        # Extract all ratings\n",
        "        all_ratings = soup.find_all('div', class_='review-ring-score__score text-bold')\n",
        "\n",
        "        # Prepare the titles list, skipping \"Latest Reviews\"\n",
        "        titles = []\n",
        "        if first_title and \"Latest Reviews\" not in first_title.text:  # Check first title\n",
        "            titles.append(first_title)\n",
        "        for title in additional_titles + original_titles:  # Combine titles\n",
        "            title_text = title.text.strip()\n",
        "            if \"Latest Reviews\" not in title_text:  # Skip \"Latest Reviews\"\n",
        "                titles.append(title)\n",
        "\n",
        "        # Collect up to top titles and ratings, removing \"Review\" and after\n",
        "        top_ten = []\n",
        "        for title, rating in zip(titles, all_ratings):\n",
        "            if title is not None:  # Check for None\n",
        "                # Remove \"Review\" and everything after it\n",
        "                title_text = title.text.split('Review')[0].strip().replace(\"Remake\", \"\").strip()\n",
        "                rating_text = rating.text.strip()\n",
        "                if title_text:  # Ensure title is not empty\n",
        "                    top_ten.append((title_text, rating_text))\n",
        "\n",
        "        return top_ten\n",
        "    else:\n",
        "        print(f\"Failed to retrieve the page {url}. Status code:\", response.status_code)\n",
        "        return []\n",
        "\n",
        "# Scrape both pages\n",
        "first_page_data = scrape_page(base_url)\n",
        "second_page_data = scrape_page(base_url + \"?page=2\")\n",
        "\n",
        "# Combine data from both pages\n",
        "all_data = first_page_data + second_page_data\n",
        "\n",
        "# Create a DataFrame\n",
        "gamespot = pd.DataFrame(all_data, columns=['Title', 'Rating'])\n",
        "\n",
        "# Output the DataFrame\n",
        "print(\"Top Reviews and Ratings DataFrame:\")\n",
        "print(gamespot)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EziOPhGe5Wqo",
        "outputId": "f4c20c9e-d019-4699-e2d5-6fcf25a3b1f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top Reviews and Ratings DataFrame:\n",
            "                                    Title Rating\n",
            "0           A Quiet Place: The Road Ahead      6\n",
            "1                      Fear The Spotlight      7\n",
            "2              Sonic X Shadow Generations      6\n",
            "3                             RetroRealms      8\n",
            "4           Mortal Kombat 1: Khaos Reigns      6\n",
            "5              Super Mario Party Jamboree      6\n",
            "6                   Backyard Baseball '97      8\n",
            "7              Dragon Ball: Sparking Zero      6\n",
            "8              Diablo 4: Vessel Of Hatred      8\n",
            "9                           Silent Hill 2      9\n",
            "10                   Metaphor: ReFantazio     10\n",
            "11                        EA Sports FC 25      6\n",
            "12                           Funko Fusion      4\n",
            "13                    God Of War Ragnarok      9\n",
            "14  The Legend Of Zelda: Echoes Of Wisdom      9\n",
            "15                                 UFO 50      9\n",
            "16            Dead Rising Deluxe Remaster      7\n",
            "17                            Frostpunk 2      8\n",
            "18                      The Plucky Squire      9\n",
            "19                          Wild Bastards      9\n",
            "20                    Squirrel With A Gun      4\n",
            "21  Marvel Vs. Capcom Fighting Collection      8\n",
            "22                               NBA 2K25      8\n",
            "23             The Casting Of Frank Stone      6\n",
            "24       Warhammer 40,000: Space Marine 2      8\n",
            "25                             Hollowbody      7\n",
            "26                              Astro Bot      9\n",
            "27      World Of Warcraft: The War Within      9\n",
            "28                      Star Wars Outlaws      6\n",
            "29                        Visions Of Mana      5\n",
            "30                          Madden NFL 25      6\n",
            "31                Tactical Breach Wizards      8\n",
            "32                     Black Myth: Wukong      8\n",
            "33                               Dustborn      5\n",
            "34                         Farewell North      7\n",
            "35                     SteamWorld Heist 2      9\n",
            "36                       Creatures Of Ava      8\n",
            "37             Thank Goodness You're Here      9\n",
            "38          EA Sports College Football 25      8\n",
            "39                   Sylvio: Black Waters      8\n",
            "40      Kunitsu-Gami: Path Of The Goddess      8\n",
            "41                   The First Descendant      3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Scraping of Metacritic reviews\n"
      ],
      "metadata": {
        "id": "i_vMqmXrQ2YP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "\n",
        "# Define the URL and headers\n",
        "url = \"https://www.metacritic.com/game/\"\n",
        "headers = {\n",
        "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
        "}\n",
        "\n",
        "# Send GET request\n",
        "response = requests.get(url, headers=headers)\n",
        "\n",
        "# Check if the request was successful\n",
        "if response.status_code == 200:\n",
        "    # Parse the HTML content\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "    # Extract game titles\n",
        "    titles = soup.find_all('h3', class_='c-globalProductCard_title g-color-gray80 g-text-xsmall')\n",
        "\n",
        "    # Extract ratings (both green and yellow)\n",
        "    ratings = soup.find_all('div', class_='c-siteReviewScore')\n",
        "\n",
        "    # Filter ratings for green and yellow\n",
        "    valid_ratings = [rating for rating in ratings if 'c-siteReviewScore_green' in rating['class'] or 'c-siteReviewScore_yellow' in rating['class']]\n",
        "\n",
        "    # Ensure the number of ratings matches the number of titles\n",
        "    if len(valid_ratings) > len(titles):\n",
        "        valid_ratings = valid_ratings[:len(titles)]\n",
        "\n",
        "    # Print the count of titles and ratings found\n",
        "    print(f\"Number of titles found: {len(titles)}\")\n",
        "    print(f\"Number of ratings found: {len(valid_ratings)}\")\n",
        "\n",
        "    # Collect top ten titles and ratings\n",
        "    top_ten = []\n",
        "    for title, rating in zip(titles[:30], valid_ratings[:30]):\n",
        "        title_text = title.text.strip()\n",
        "        rating_text = rating.find('span').text.strip()  # Get the rating score from the <span>\n",
        "        top_ten.append((title_text, rating_text))\n",
        "\n",
        "    # Create a DataFrame\n",
        "    metacritic = pd.DataFrame(top_ten, columns=['Title', 'Rating'])\n",
        "    metacritic['Rating'] = metacritic['Rating'].astype(float) / 10\n",
        "\n",
        "    # Output the DataFrame\n",
        "    print(\"Top 10 Reviews and Ratings DataFrame:\")\n",
        "    print(metacritic)\n",
        "\n",
        "else:\n",
        "    print(\"Failed to retrieve the page. Status code:\", response.status_code)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cx92b6l4Q1zx",
        "outputId": "c6dc09d8-e9de-44df-e508-8f087466fad6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of titles found: 59\n",
            "Number of ratings found: 59\n",
            "Top 10 Reviews and Ratings DataFrame:\n",
            "                                   Title  Rating\n",
            "0                     Fear the Spotlight     8.1\n",
            "1                   Unknown 9: Awakening     6.1\n",
            "2                              Citadelum     6.8\n",
            "3                Arizona Sunshine Remake     7.7\n",
            "4             Super Mario Party Jamboree     8.2\n",
            "5                   MechWarrior 5: Clans     8.0\n",
            "6                               9 R.I.P.     8.3\n",
            "7                Just Dance 2025 Edition     7.1\n",
            "8                                   Neva     8.7\n",
            "9          Nikoderiko: The Magical World     8.1\n",
            "10                   New World: Aeternum     8.0\n",
            "11         Transformers: Galactic Trials     6.4\n",
            "12      Starship Troopers: Extermination     7.7\n",
            "13                                Europa     7.1\n",
            "14                            Undisputed     9.4\n",
            "15                  Metaphor: ReFantazio     8.1\n",
            "16           Dragon Ball: Sparking! Zero     8.6\n",
            "17                         Silent Hill 2     7.3\n",
            "18                           Dead Season     8.4\n",
            "19           Diablo IV: Vessel of Hatred     8.0\n",
            "20             Call of Duty: Black Ops 6     8.1\n",
            "21            Sonic x Shadow Generations     9.6\n",
            "22                         Ys X: Nordics     9.6\n",
            "23      Life is Strange: Double Exposure     9.4\n",
            "24             Dragon Age: The Veilguard     9.4\n",
            "25          Horizon Zero Dawn Remastered     9.4\n",
            "26            Mario & Luigi: Brothership     9.4\n",
            "27                           Slitterhead     9.4\n",
            "28  S.T.A.L.K.E.R. 2: Heart of Chornobyl     9.3\n",
            "29                         Marvel Rivals     9.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Attempt to scrape ScreenRant reviews and ratings"
      ],
      "metadata": {
        "id": "7Fr60W6AE3ha"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import time\n",
        "\n",
        "# User-Agent header to mimic a browser request\n",
        "headers = {\n",
        "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
        "}\n",
        "\n",
        "# Base URL for the game reviews\n",
        "base_url = 'https://screenrant.com/game-reviews/'\n",
        "\n",
        "game_reviews = []\n",
        "\n",
        "# Loop through a range of pages\n",
        "for page in range(1, 4):  # Change 4 to the number of pages you want to scrape\n",
        "    print(f\"Fetching page {page}...\")\n",
        "    response = requests.get(f\"{base_url}{page}/\", headers=headers)\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "        # Find all the game reviews\n",
        "        reviews = soup.find_all('h5', class_='display-card-title')\n",
        "\n",
        "        for review in reviews:\n",
        "            title_tag = review.find('a')\n",
        "            title = title_tag.get_text(strip=True)\n",
        "            review_link = 'https://screenrant.com' + title_tag['href']\n",
        "\n",
        "            try:\n",
        "                review_response = requests.get(review_link, headers=headers)\n",
        "                review_response.raise_for_status()\n",
        "\n",
        "                review_soup = BeautifulSoup(review_response.content, 'html.parser')\n",
        "\n",
        "                # Find the Screen Rant rating\n",
        "                rating_div = review_soup.find('div', class_='w-rating')\n",
        "                if rating_div:\n",
        "                    screenrant_rating = rating_div.find('div', class_='rate-number')\n",
        "                    if screenrant_rating:\n",
        "                        rating_number = screenrant_rating.get_text(strip=True).split('/')[0]\n",
        "                        rating_text = rating_number\n",
        "                    else:\n",
        "                        print(f\"Screen Rant rating not found for {title}. Skipping...\")\n",
        "                        continue  # Skip if rating not found\n",
        "                else:\n",
        "                    print(f\"Rating section not found for {title}. Skipping...\")\n",
        "                    continue  # Skip if rating section not found\n",
        "\n",
        "                title = title.split(\"Review\")[0].strip()\n",
        "\n",
        "                # Remove the word \"Remake\" from the title\n",
        "                title = title.replace(\"Remake\", \"\").strip()\n",
        "\n",
        "                game_reviews.append({'Title': title, 'Rating': rating_text})\n",
        "\n",
        "                time.sleep(1)  # Be polite to the server\n",
        "            except requests.exceptions.RequestException as e:\n",
        "                print(f\"Failed to fetch {review_link}: {e}\")\n",
        "    else:\n",
        "        print(f\"Failed to fetch page {page}.\")\n",
        "\n",
        "# Create a DataFrame from the results\n",
        "screenrant = pd.DataFrame(game_reviews)\n",
        "\n",
        "# Check for ratings that are '0' and print titles\n",
        "problematic_titles = screenrant[screenrant['Rating'] == '0']\n",
        "if not problematic_titles.empty:\n",
        "    print(\"Titles with a rating of 0:\")\n",
        "    print(problematic_titles)\n",
        "\n",
        "# Print the DataFrame\n",
        "print(screenrant)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JapH6PaKE13t",
        "outputId": "6a336f53-f3f8-4569-fc52-bd3c1a40aa3f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fetching page 1...\n",
            "Rating section not found for Metaphor: ReFantazio Preview: Combining The Best Of SMT & Persona Into The Next Big JRPG. Skipping...\n",
            "Fetching page 2...\n",
            "Rating section not found for Metaphor: ReFantazio Preview: Combining The Best Of SMT & Persona Into The Next Big JRPG. Skipping...\n",
            "Rating section not found for Dustborn Review: Never Really Delivering On The Promise. Skipping...\n",
            "Rating section not found for The Crush House Review: A Scintillating Social Sim Fever Dream. Skipping...\n",
            "Rating section not found for Hidden Through Time 2: Discovery Review - More Like An Expansion. Skipping...\n",
            "Rating section not found for Eden Genesis Review: Unnecessarily Cumbersome But With A Smart Challenge. Skipping...\n",
            "Screen Rant rating not found for Star Wars: Bounty Hunter Review - Jango Fett Might Not Be Worth The Remaster. Skipping...\n",
            "Rating section not found for I Think The Razer Huntsman V3 Pro's Snap Tap Actually Made Me A Better Gamer. Skipping...\n",
            "Fetching page 3...\n",
            "Rating section not found for The Sims 4 Lovestruck Review: A Bit Of A Hot Mess. Skipping...\n",
            "Rating section not found for Hearthstone Perils In Paradise Doesn't Fix Its Biggest Problem But I'm Strangely Fine With It. Skipping...\n",
            "Rating section not found for Final Fantasy XIV: Dawntrail: An Expectation That Still Surprises. Skipping...\n",
            "Rating section not found for Stray Gods: Orpheus Review - Continuing The Original's Brilliance. Skipping...\n",
            "                                           Title Rating\n",
            "0                           Metaphor: ReFantazio      9\n",
            "1                                           Neva      9\n",
            "2                     Starfield: Shattered Space      5\n",
            "3                    Dragon Ball: Sparking! Zero      9\n",
            "4                     Diablo 4: Vessel Of Hatred      7\n",
            "5   SpongeBob SquarePants: The Patrick Star Game      6\n",
            "6                                  Silent Hill 2      8\n",
            "7                             Throne And Liberty      6\n",
            "8                                EA SPORTS FC 25      8\n",
            "9          The Legend of Zelda: Echoes of Wisdom      9\n",
            "10                                   Frostpunk 2      8\n",
            "11                             The Plucky Squire      7\n",
            "12                   Dead Rising Deluxe Remaster      9\n",
            "13             Harry Potter: Quidditch Champions      8\n",
            "14                                      NBA 2K25      8\n",
            "15                                     Astro Bot      9\n",
            "16              Warhammer 40,000: Space Marine 2      8\n",
            "17                 The Casting Of Frank Stone PC      5\n",
            "18                               Visions of Mana      7\n",
            "19              Warhammer 40,000: Space Marine 2      8\n",
            "20                 The Casting Of Frank Stone PC      5\n",
            "21                               Visions of Mana      7\n",
            "22                             Star Wars Outlaws      8\n",
            "23                                       Concord      6\n",
            "24                                 Madden NFL 25      7\n",
            "25                            Black Myth: Wukong      6\n",
            "26                                    Deathbound      6\n",
            "27                                   Cat Quest 3      9\n",
            "28                              Creatures of Ava      8\n",
            "29                            SteamWorld Heist 2      9\n",
            "30                   Thank Goodness You're Here!      8\n",
            "31                                     Weyrdlets      8\n",
            "32                             Vampire Therapist      7\n",
            "33                  Flintlock: The Siege of Dawn      7\n",
            "34                           College Football 25      8\n",
            "35                                  Space Prison      7\n",
            "36                        Dungeons of Hinterburg      8\n",
            "37     Nintendo World Championships: NES Edition      8\n",
            "38                                         Flock      9\n",
            "39             Kunitsu-Gami: Path of the Goddess      8\n",
            "40                                         SCHiM      6\n",
            "41                                    Anger Foot      8\n",
            "42                Spy X Anya: Operation Memories      8\n",
            "43                                        Looped      3\n",
            "44                                Fruit Mountain      6\n",
            "45                                     NeoSprint      7\n",
            "46                          Still Wakes The Deep      7\n",
            "47                          Luigi's Mansion 2 HD      7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"top IGN newest reviews\")\n",
        "print(ign)\n",
        "print(\" \")\n",
        "print(\"top Opencritic newest reviews\")\n",
        "print(opencritic_df)\n",
        "print(\" \")\n",
        "print(\"top Gamespot newest reviews\")\n",
        "print(gamespot)\n",
        "print(\" \")\n",
        "print(\"top Metacritic newest reviews\")\n",
        "print(metacritic)\n",
        "print(\" \")\n",
        "print(\"top ScreenRant newest reviews\")\n",
        "print(screenrant)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AEgP6A7j8puW",
        "outputId": "70bfafa1-3372-491e-9598-1f0257f67281"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "top IGN newest reviews\n",
            "                              Title Rating\n",
            "0           Kong: Survivor Instinct      5\n",
            "1     A Quiet Place: The Road Ahead      7\n",
            "2        Sonic X Shadow Generations      9\n",
            "3  Starship Troopers: Extermination      6\n",
            "4              Unknown 9: Awakening      5\n",
            "5              MechWarrior 5: Clans      8\n",
            "6        Super Mario Party Jamboree      9\n",
            "7       Dragon Ball: Sparking! Zero      7\n",
            "8                        Until Dawn      5\n",
            " \n",
            "top Opencritic newest reviews\n",
            "                                              Title  Rating\n",
            "0                           Kong: Survivor Instinct     6.6\n",
            "1                        Sonic X Shadow Generations     7.9\n",
            "2                                Fear The Spotlight     8.1\n",
            "3   Teenage Mutant Ninja Turtles: Mutants Unleashed     7.5\n",
            "4                        Super Mario Party Jamboree     8.1\n",
            "5                              MechWarrior 5: Clans     7.9\n",
            "6                         Killing Time: Resurrected     8.5\n",
            "7                              Unknown 9: Awakening     6.4\n",
            "8                                RetroRealms Arcade     6.9\n",
            "9                           Arizona Sunshine Remake     7.8\n",
            "10                    A Quiet Place: The Road Ahead     6.6\n",
            "11                                             Neva     8.7\n",
            "12                    Nikoderiko: The Magical World     7.5\n",
            "13                          Just Dance 2025 Edition     7.3\n",
            "14                             Drova - Forsaken Kin     7.0\n",
            "15                             Metaphor: ReFantazio     9.2\n",
            "16                                           Europa     7.5\n",
            "17                    Transformers: Galactic Trials     4.8\n",
            "18                       Dragon Ball Sparking! Zero     8.3\n",
            "19                                       Amber Isle     6.8\n",
            "20                       Sky Oceans: Wings for Hire     4.3\n",
            "21                                    Silent Hill 2     8.7\n",
            "22                      Diablo IV: Vessel of Hatred     8.5\n",
            "23                                      Dead Season     7.5\n",
            "24                                  Phoenix Springs     7.5\n",
            "25                                           NHL 25     6.8\n",
            "26                                       Until Dawn     7.0\n",
            "27             Sword Art Online: Fractured Daydream     6.8\n",
            "28                                      KILL KNIGHT     8.4\n",
            "29                                     Rogue Waters     8.3\n",
            "30                       Starfield: Shattered Space     6.1\n",
            "31                               Throne and Liberty     7.1\n",
            "32                                         REYNATIS     6.1\n",
            "33              Looney Tunes: Wacky World of Sports     4.9\n",
            "34                                      Ravenswatch     8.3\n",
            "35            The Legend of Zelda: Echoes of Wisdom     8.5\n",
            "36                                        Iron Meat     8.2\n",
            " \n",
            "top Gamespot newest reviews\n",
            "                                    Title Rating\n",
            "0           A Quiet Place: The Road Ahead      6\n",
            "1                      Fear The Spotlight      7\n",
            "2              Sonic X Shadow Generations      6\n",
            "3                             RetroRealms      8\n",
            "4           Mortal Kombat 1: Khaos Reigns      6\n",
            "5              Super Mario Party Jamboree      6\n",
            "6                   Backyard Baseball '97      8\n",
            "7              Dragon Ball: Sparking Zero      6\n",
            "8              Diablo 4: Vessel Of Hatred      8\n",
            "9                           Silent Hill 2      9\n",
            "10                   Metaphor: ReFantazio     10\n",
            "11                        EA Sports FC 25      6\n",
            "12                           Funko Fusion      4\n",
            "13                    God Of War Ragnarok      9\n",
            "14  The Legend Of Zelda: Echoes Of Wisdom      9\n",
            "15                                 UFO 50      9\n",
            "16            Dead Rising Deluxe Remaster      7\n",
            "17                            Frostpunk 2      8\n",
            "18                      The Plucky Squire      9\n",
            "19                          Wild Bastards      9\n",
            "20                    Squirrel With A Gun      4\n",
            "21  Marvel Vs. Capcom Fighting Collection      8\n",
            "22                               NBA 2K25      8\n",
            "23             The Casting Of Frank Stone      6\n",
            "24       Warhammer 40,000: Space Marine 2      8\n",
            "25                             Hollowbody      7\n",
            "26                              Astro Bot      9\n",
            "27      World Of Warcraft: The War Within      9\n",
            "28                      Star Wars Outlaws      6\n",
            "29                        Visions Of Mana      5\n",
            "30                          Madden NFL 25      6\n",
            "31                Tactical Breach Wizards      8\n",
            "32                     Black Myth: Wukong      8\n",
            "33                               Dustborn      5\n",
            "34                         Farewell North      7\n",
            "35                     SteamWorld Heist 2      9\n",
            "36                       Creatures Of Ava      8\n",
            "37             Thank Goodness You're Here      9\n",
            "38          EA Sports College Football 25      8\n",
            "39                   Sylvio: Black Waters      8\n",
            "40      Kunitsu-Gami: Path Of The Goddess      8\n",
            "41                   The First Descendant      3\n",
            " \n",
            "top Metacritic newest reviews\n",
            "                                   Title  Rating\n",
            "0                     Fear the Spotlight     8.1\n",
            "1                   Unknown 9: Awakening     6.1\n",
            "2                              Citadelum     6.8\n",
            "3                Arizona Sunshine Remake     7.7\n",
            "4             Super Mario Party Jamboree     8.2\n",
            "5                   MechWarrior 5: Clans     8.0\n",
            "6                               9 R.I.P.     8.3\n",
            "7                Just Dance 2025 Edition     7.1\n",
            "8                                   Neva     8.7\n",
            "9          Nikoderiko: The Magical World     8.1\n",
            "10                   New World: Aeternum     8.0\n",
            "11         Transformers: Galactic Trials     6.4\n",
            "12      Starship Troopers: Extermination     7.7\n",
            "13                                Europa     7.1\n",
            "14                            Undisputed     9.4\n",
            "15                  Metaphor: ReFantazio     8.1\n",
            "16           Dragon Ball: Sparking! Zero     8.6\n",
            "17                         Silent Hill 2     7.3\n",
            "18                           Dead Season     8.4\n",
            "19           Diablo IV: Vessel of Hatred     8.0\n",
            "20             Call of Duty: Black Ops 6     8.1\n",
            "21            Sonic x Shadow Generations     9.6\n",
            "22                         Ys X: Nordics     9.6\n",
            "23      Life is Strange: Double Exposure     9.4\n",
            "24             Dragon Age: The Veilguard     9.4\n",
            "25          Horizon Zero Dawn Remastered     9.4\n",
            "26            Mario & Luigi: Brothership     9.4\n",
            "27                           Slitterhead     9.4\n",
            "28  S.T.A.L.K.E.R. 2: Heart of Chornobyl     9.3\n",
            "29                         Marvel Rivals     9.3\n",
            " \n",
            "top ScreenRant newest reviews\n",
            "                                           Title Rating\n",
            "0                           Metaphor: ReFantazio      9\n",
            "1                                           Neva      9\n",
            "2                     Starfield: Shattered Space      5\n",
            "3                    Dragon Ball: Sparking! Zero      9\n",
            "4                     Diablo 4: Vessel Of Hatred      7\n",
            "5   SpongeBob SquarePants: The Patrick Star Game      6\n",
            "6                                  Silent Hill 2      8\n",
            "7                             Throne And Liberty      6\n",
            "8                                EA SPORTS FC 25      8\n",
            "9          The Legend of Zelda: Echoes of Wisdom      9\n",
            "10                                   Frostpunk 2      8\n",
            "11                             The Plucky Squire      7\n",
            "12                   Dead Rising Deluxe Remaster      9\n",
            "13             Harry Potter: Quidditch Champions      8\n",
            "14                                      NBA 2K25      8\n",
            "15                                     Astro Bot      9\n",
            "16              Warhammer 40,000: Space Marine 2      8\n",
            "17                 The Casting Of Frank Stone PC      5\n",
            "18                               Visions of Mana      7\n",
            "19              Warhammer 40,000: Space Marine 2      8\n",
            "20                 The Casting Of Frank Stone PC      5\n",
            "21                               Visions of Mana      7\n",
            "22                             Star Wars Outlaws      8\n",
            "23                                       Concord      6\n",
            "24                                 Madden NFL 25      7\n",
            "25                            Black Myth: Wukong      6\n",
            "26                                    Deathbound      6\n",
            "27                                   Cat Quest 3      9\n",
            "28                              Creatures of Ava      8\n",
            "29                            SteamWorld Heist 2      9\n",
            "30                   Thank Goodness You're Here!      8\n",
            "31                                     Weyrdlets      8\n",
            "32                             Vampire Therapist      7\n",
            "33                  Flintlock: The Siege of Dawn      7\n",
            "34                           College Football 25      8\n",
            "35                                  Space Prison      7\n",
            "36                        Dungeons of Hinterburg      8\n",
            "37     Nintendo World Championships: NES Edition      8\n",
            "38                                         Flock      9\n",
            "39             Kunitsu-Gami: Path of the Goddess      8\n",
            "40                                         SCHiM      6\n",
            "41                                    Anger Foot      8\n",
            "42                Spy X Anya: Operation Memories      8\n",
            "43                                        Looped      3\n",
            "44                                Fruit Mountain      6\n",
            "45                                     NeoSprint      7\n",
            "46                          Still Wakes The Deep      7\n",
            "47                          Luigi's Mansion 2 HD      7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Attempt at implementing a function that singles out titles at appear in all four dataframes and takes the average rating. (Having trouble getting consistent expansion of the list between the dataframes. Could be a HTML issue. The function below should work as all it does is the merge the rows from all four dataframes and picks out the titles that exists in all four dataframes)"
      ],
      "metadata": {
        "id": "ia0rRmPsSelp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "def average_common_ratings(ign, opencritic, gamespot, metacritic, screenrant):\n",
        "    # Check if required columns are present\n",
        "    required_columns = ['Title', 'Rating']\n",
        "    for df in [ign, opencritic, gamespot, metacritic, screenrant]:\n",
        "        if not all(col in df.columns for col in required_columns):\n",
        "            raise ValueError(\"All DataFrames must contain 'Title' and 'Rating' columns.\")\n",
        "\n",
        "    # Merge the DataFrames on 'Title' using inner joins to keep only common titles\n",
        "    merged_df = (ign.merge(opencritic, on='Title', how='inner', suffixes=('_ign', '_opencritic'))\n",
        "                  .merge(gamespot, on='Title', how='inner', suffixes=('', '_gamespot'))\n",
        "                  .merge(metacritic, on='Title', how='inner', suffixes=('', '_metacritic'))\n",
        "                  .merge(screenrant, on='Title', how='inner', suffixes=('', '_screenrant')))\n",
        "\n",
        "    # Rename 'Rating' column from gamespot and screenrant for consistency\n",
        "    merged_df = merged_df.rename(columns={'Rating': 'Rating_gamespot', 'Rating_screenrant': 'Rating_screenrant'})\n",
        "\n",
        "    # List of rating columns\n",
        "    rating_columns = ['Rating_ign', 'Rating_opencritic', 'Rating_gamespot', 'Rating_metacritic', 'Rating_screenrant']\n",
        "\n",
        "    # Convert rating columns to numeric, handling errors by coercing to NaN\n",
        "    for col in rating_columns:\n",
        "        merged_df[col] = pd.to_numeric(merged_df[col], errors='coerce')\n",
        "\n",
        "    # Calculate average rating\n",
        "    merged_df['Average_Rating'] = merged_df[rating_columns].mean(axis=1, skipna=True)\n",
        "\n",
        "    # Filter for valid average ratings\n",
        "    result = merged_df[merged_df['Average_Rating'].notnull()][['Title', 'Average_Rating']]\n",
        "\n",
        "    return result\n",
        "\n",
        "# Example usage:\n",
        "# average_ratings = average_common_ratings(ign, opencritic, gamespot, metacritic, screenrant)\n",
        "# print(average_ratings)\n"
      ],
      "metadata": {
        "id": "rPlt8CP7SeSp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "average_ratings = average_common_ratings(ign, opencritic_df, gamespot, metacritic, screenrant)\n",
        "print(average_ratings)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iiexn3fHK-fi",
        "outputId": "bb40618c-686c-4672-cb0f-c90dc6cbdbb4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Empty DataFrame\n",
            "Columns: [Title, Average_Rating]\n",
            "Index: []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Attempt at implementing a function that requires a title to exist in at least 3 of the 4 dataframes. This is a work around for not being able to expand the dataframes at the moment."
      ],
      "metadata": {
        "id": "yTHyUft1_iqk"
      }
    },
    {
      "source": [
        "import pandas as pd\n",
        "\n",
        "def average_common_ratings(ign, opencritic, gamespot, metacritic, screenrant):\n",
        "    # Merge the DataFrames on 'Title' to find common titles with outer joins\n",
        "    merged_df = (ign.merge(opencritic, on='Title', how='outer', suffixes=('_ign', '_opencritic'))\n",
        "                  .merge(gamespot, on='Title', how='outer', suffixes=('', '_gamespot'))  # Add suffixes here\n",
        "                  .merge(metacritic, on='Title', how='outer', suffixes=('', '_metacritic'))  # Add suffixes here\n",
        "                  .merge(screenrant, on='Title', how='outer', suffixes=('', '_screenrant')))  # Include ScreenRant\n",
        "\n",
        "    # Rename the 'Rating' column to 'Rating_gamespot' and 'Rating' from ScreenRant for consistency\n",
        "    merged_df = merged_df.rename(columns={\n",
        "        'Rating': 'Rating_gamespot',\n",
        "        'Rating_screenrant': 'Rating_screenrant'\n",
        "    })\n",
        "\n",
        "    # List of rating columns\n",
        "    rating_columns = ['Rating_ign', 'Rating_opencritic', 'Rating_gamespot', 'Rating_metacritic', 'Rating_screenrant']\n",
        "\n",
        "    # Convert rating columns to numeric, handling errors by coercing to NaN\n",
        "    for col in rating_columns:\n",
        "        merged_df[col] = pd.to_numeric(merged_df[col], errors='coerce')\n",
        "\n",
        "    # Count the number of non-null ratings\n",
        "    rating_counts = merged_df[rating_columns].notnull().sum(axis=1)\n",
        "\n",
        "    # Filter for titles with at least three ratings\n",
        "    merged_df['Average_Rating'] = merged_df[rating_columns].mean(axis=1, skipna=True)\n",
        "    result = merged_df[(rating_counts >= 3) & (merged_df['Average_Rating'].notnull())][['Title', 'Average_Rating']]\n",
        "\n",
        "    # Sort the result by 'Average_Rating' in descending order\n",
        "    result = result.sort_values(by='Average_Rating', ascending=False)\n",
        "\n",
        "    return result\n",
        "\n",
        "# Example usage:\n",
        "# average_ratings = average_common_ratings(ign, opencritic, gamespot, metacritic, screenrant)\n",
        "# print(average_ratings)\n"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "3yOhKAuY_Dcr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "average_ratings = average_common_ratings(ign, opencritic_df, gamespot, metacritic, screenrant)\n",
        "print(average_ratings)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BD6fzYPgUDgG",
        "outputId": "eae9b5e7-e377-488e-c01a-e6c1c59af6cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                             Title  Average_Rating\n",
            "59            Metaphor: ReFantazio        9.075000\n",
            "64                            Neva        8.800000\n",
            "76                   Silent Hill 2        8.250000\n",
            "23     Dragon Ball: Sparking! Zero        8.200000\n",
            "58            MechWarrior 5: Clans        7.966667\n",
            "90      Super Mario Party Jamboree        7.825000\n",
            "79      Sonic X Shadow Generations        7.633333\n",
            "1    A Quiet Place: The Road Ahead        6.533333\n",
            "109           Unknown 9: Awakening        5.833333\n"
          ]
        }
      ]
    }
  ]
}